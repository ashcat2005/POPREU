{
 "metadata": {
  "name": "",
  "signature": "sha256:e9c0a999807c67a12edf1fc007ee1e4ad88f88cf43ef5bb129bac6c05e2711c2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### This code is used to classify a large CFHTLenS dataset with a trained MlLib random forest model ###\n",
      "\n",
      "The classification probabilities with their respective IDs will be saved in a directory called \"outputs\" and will have file names corresponding to the names of the input CSV files. \n",
      "\n",
      "Dependencies:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyspark.mllib.tree import RandomForest\n",
      "from pyspark.mllib.tree import RandomForestModel\n",
      "from pyspark.mllib.tree import DecisionTreeModel\n",
      "from pyspark.mllib.util import MLUtils\n",
      "from pyspark import SparkContext\n",
      "from pyspark import SparkConf\n",
      "import subprocess"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This function takes the name of a csv file of CFHTLenS data and returns 2 RDDs. The first RDD contains the IDs of each object. The second RDD contains the color and magnitude information for each object. Note that it is absolutely crucial to unpersist the large RDD of rawData."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def to_RDD(filename):\n",
      "        rawData = selfsc.textFile(filename+\".csv\")\n",
      "        header = rawData.first()\n",
      "        rawData = rawData.filter(lambda x: x!=header)\n",
      "        data = rawData.map(get_data)\n",
      "        ID = rawData.map(get_id)\n",
      "        rawData.unpersist()\n",
      "        return ID, data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The following 3 functions all help with the data preprocessing for the to_RDD function."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_feature_idx(filename):\n",
      "        header = subprocess.check_output('hadoop fs -cat '+filename+' | head -1', shell = True)\n",
      "        header = header.split(\",\")\n",
      "        header_idx = {x: header.index(x)-1 for x in header}\n",
      "        idx = []\n",
      "        for f in features:\n",
      "                idx.append(header_idx[f])\n",
      "        return idx\n",
      "\n",
      "def get_data(line):\n",
      "        #get the raw data minus the ID from the line\n",
      "        raw_data = line.split(\",\")[1:]\n",
      "\n",
      "        #put data back into a string for processing\n",
      "        raw_string = ''\n",
      "        for x in raw_data:\n",
      "                raw_string += x+\",\"\n",
      "        raw_data = raw_string[:-1]\n",
      "\n",
      "        #remove quotation marks and replace commas with semicolons in the quotation marks\n",
      "        raw_data = raw_data.split('\"')\n",
      "        for i in range(1,len(raw_data),2):\n",
      "                raw_data[i] = raw_data[i].replace(',',\";\")\n",
      "\n",
      "        #put data back into a string for processing\n",
      "        no_quotes = \"\"\n",
      "        for x in raw_data:\n",
      "                no_quotes += x\n",
      "\n",
      "        #get processed raw data without quotes and put it into a list\n",
      "        raw_data = no_quotes.split(\",\")\n",
      "\n",
      "        #get data from wanted features\n",
      "        data = []\n",
      "        for i in selffeature_idx:\n",
      "                data.append(float(raw_data[i]))\n",
      "\n",
      "        #calculate and add colors\n",
      "        for i in range(len(data)-1):\n",
      "                data.append(data[i+1]-data[i])\n",
      "        return data\n",
      "\n",
      "\n",
      "def get_id(line):\n",
      "        return line.split(\",\")[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Saves an RDD as the specified filename"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def save( rdd, filename):\n",
      "        try:\n",
      "                shutil.rmtree(filename)\n",
      "        except Exception:\n",
      "                pass\n",
      "        rdd.saveAsTextFile(filename)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Classifies and saves the classifications for the given RDDs of features and IDs"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def classify(ids, feature_data, filename) :\n",
      "        print \"    probTest_classify\"\n",
      "        #probs = binary_classify(feature_data)\n",
      "        probs = probs_classify(feature_data)\n",
      "        print \"    zip\"\n",
      "        id_probs = ids.zip(probs)\n",
      "        print \"    SAVING\"\n",
      "        save(id_probs, 'output/'+filename+'answers')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Returns an RDD of classification probabilities for the input data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def probs_classify (data) :\n",
      "        trees = selfmodel._java_model.trees()\n",
      "        ntrees = selfmodel.numTrees()\n",
      "        scores = DecisionTreeModel(trees[0]).predict(data)\n",
      "        for i in range(1, ntrees) :\n",
      "                dtm = DecisionTreeModel(trees[i])\n",
      "                scores = scores.zip(dtm.predict(data))\n",
      "                scores = scores.map(lambda x: x[0]+x[1])\n",
      "                print 'Classified with tree number  ' + str(i)\n",
      "        return scores.map(lambda x: x/ntrees)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Returns an RDD of binary classifications for the input data. Note that this is much faster than probs_classify."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def binary_classify(feature_data) :\n",
      "        ans = selfmodel.predict(feature_data)\n",
      "        return ans"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Calls classify for every csv file in the field_list."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def main():\n",
      "        for filename in selffilenames:\n",
      "                print filename +\" to RDD\"\n",
      "                ID, data = to_RDD(filename)\n",
      "                print \"classifying  \"+ filename\n",
      "                classify(ID, data, filename)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Starts the Spark Context."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "conf = SparkConf().setAppName(\"stargalaxy\").set(\"spark.rdd.compress\",\"true\").set(\"spark.storage.memoryFraction\",\"1\").set(\"spark.core.connection.ack.wait.timeout\",\"1000\").set(\"spark.akka.frameSize\",\"1000\").set(\"spark.executor.memory\",\"1g\")\n",
      "selfsc = SparkContext(conf = conf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This list should contain the path to every csv file of data that you wish to classify. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "field_list = ['W1m0m0', 'W1m0m1', 'W1m0m2', 'W1m0m3']\n",
      "selffilenames = field_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This list should contain the column header of every feature that you wish to include in the classification (including ID)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features = ['id','MAG_u', 'MAG_g', 'MAG_r', 'MAG_i', 'MAG_z']\n",
      "selffeature_idx = get_feature_idx(selffilenames[0]+\".csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This loads a trained random forest model. selfmodel_file should be the path to the directory of your saved model."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "selfmodel_file = '4trees'\n",
      "selfmodel = RandomForestModel.load(selfsc, selfmodel_file)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Calls main"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "main()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}