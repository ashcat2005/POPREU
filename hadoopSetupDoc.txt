Taken from http://clemmblog.azurewebsites.net/building-a-multi-node-hadoop-v2-cluster-with-ubuntu-on-windows-azure/

Set up Azure:
-navigate to http://www.microsoftazurepass.com/ and follow their instructions

Login to Azure:
-https://manage.windowsazure.com/

Creating a virtual network:
Source:   https://azure.microsoft.com/en-us/documentation/articles/create-virtual-network/
All VMs in our Hadoop cluster will be deployed to a single virtual network in order to achieve network visibility among the nodes.
To create this example cloud-only virtual network, do the following:
-Log in to the Management Portal.
-In the lower left-hand corner of the screen, click New > Network Services >
Virtual Network, and then click Custom Create to begin the configuration wizard.
-On the Virtual Network Details page, enter the following information:
-Name - Type hadoopnet.
-Region - East US 2
-Click the next arrow on the lower right.
-On the DNS Servers and VPN Connectivity page, click the next arrow on the lower right. Azure will assign an Internet-based Azure DNS server to new virtual machines that are added to this virtual network, which will allow them to access Internet resources.
	 -On the Virtual Network Address Spaces page, configure the following:
		-For Address Space, select /8 in CIDR (ADDRESS COUNT)
		-For subnets, type hadoop over the existing name and 10.0.0.0 for the starting
IP, then select /24(256) in the CIDR (ADDRESS COUNT). 

Build an Ubuntu Image:
	-In the lower left-hand corner of the screen, click New > Compute > Virtual Machine > From Gallery
	-On the Choose an Image page, select Ubuntu Server 12.04 LTS and click the right arrow
	-On the Virtual machine configuration page, set the following:
		-Virtual Machine Name: hdtemplate
		-Size: A1
		-New User Name: hduser
		-Authentication:
			-uncheck upload compatible ssh key for authentication
			-check provide a password
			-New password: <your choice>
		-click on the arrow on the lower right
	-On the second Virtual machine configuration page, set the following:
		-CLOUD SERVICE: Create a new cloud service
		-CLOUD SERVICE DNS NAME: <your choice>
		-REGION/AFFINITY GROUP/VIRTUAL NETWORK: hadoopnet
		-VIRTUAL NETWORK SUBNETS: hadoop
	-click the right arrow to finish

	-SSH into hdtemplate using PuTTy or Terminal:
		-To find the IP Address:
			-navigate to VIRTUAL MACHINES found on the left hand panel
			-click on hdtemplate
			-click on dashboard
			-on the right hand side PUBLIC VIRTUAL IP (VIP) ADDRESS is the IP you want
		-SSH using the username hduser
	-Install Java
		sudo add-apt-repository ppa:webupd8team/java
		sudo apt-get update
		sudo apt-get install oracle-java7-installer
		sudo apt-get install oracle-java7-set-default
	-Install Hadoop
		wget http://apache.spinellicreations.com/hadoop/common/hadoop-2.6.0/hadoop-2.6.0.tar.gz
		tar -xvzf hadoop-2.6.0.tar.gz
		sudo mv hadoop-2.6.0 /usr/local
	-Set Environment Variables for Java & Hadoop
		-to edit the .bashrc file, execute “vi .bashrc” 
		-to enter insert mode in VI press “i”
		-at the end of the .bashrc file add the following:

			export HADOOP_PREFIX=/usr/local/hadoop-2.6.0
			export HADOOP_HOME=/usr/local/hadoop-2.6.0
			export HADOOP_MAPRED_HOME=${HADOOP_HOME}
			export HADOOP_COMMON_HOME=${HADOOP_HOME}
			export HADOOP_HDFS_HOME=${HADOOP_HOME}
			export YARN_HOME=${HADOOP_HOME}
			export HADOOP_CONF_DIR=${HADOOP_HOME}/etc/hadoop

			# Native Path
			export HADOOP_COMMON_LIB_NATIVE_DIR=${HADOOP_PREFIX}/lib/native
			export HADOOP_OPTS="-Djava.library.path=$HADOOP_PREFIX/lib"

			#Java path
			export JAVA_HOME=/usr/lib/jvm/java-7-oracle

			# Add Hadoop bin/ directory to PATH
			export PATH=$PATH:$HADOOP_HOME/bin:$JAVA_PATH/bin:$HADOOP_HOME/sbin

		-to exit and save press “esc” and type “:wq”
		-cd  $HADOOP_HOME/etc/hadoop 
		-vi hadoop-env.sh
			-add “export JAVA_HOME=/usr/lib/jvm/java-7-oracle” to the file
		-vi core-site
			- remove the <configuration> and </configuration> tags
			- insert the following:

				<configuration> 
					<property> 
						<name>fs.default.name</name> 
						<value>hdfs://master:9000</value> 
					</property> 
					<property> 
						<name>hadoop.tmp.dir</name> 
						<value>/home/hduser/tmp</value> 
					</property> 
				</configuration>

	-vi hdfs-site
		-remove the <configuration> and </configuration> tags
		- insert the following:

			<configuration> 
				<property> 
					<name>dfs.replication</name> 
					<value>2</value>
				 </property> 
				<property> 
					<name>dfs.namenode.name.dir</name> <value>file:/home/hduser/hdfs/namenode</value> 
				</property> 
				<property> 
					<name>dfs.datanode.data.dir</name> 
					<value>file:/home/hduser/hdfs/datanode</value> 
				</property> 
			</configuration>

		-the value for dfs.replication is the number of replicas you want to keep in your HDFS file system. As we will start with two slave nodes let’s set it to 2
		-mkdir /home/hduser/hdfs
		-mkdir /home/hduser/hdfs/namenode
		-mkdir /home/hduser/hdfs/datanode
	-cp mapred-site.xml.template mapred-site.xml
	-vi mapred-site.xml
		-remove the <configuration> and </configuration> tags
		- insert the following:
			<configuration> 
				<property> 
					<name>mapreduce.framework.name</name> 
					<value>yarn</value> 
				</property> 
			</configuration>
	
	-vi yarn-site.xml
		-remove the <configuration> and </configuration> tags
		- insert the following:

			<configuration> 
				<property> 
					<name>yarn.nodemanager.aux-services</name> 
					<value>mapreduce_shuffle</value> 
				</property> 
				<property> 
					<name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name> 
					<value>org.apache.hadoop.mapred.ShuffleHandler</value> 
				</property> 
				<property> 
					<name>yarn.resourcemanager.resource-tracker.address</name> 
					<value>master:8031</value> 
				</property>
				<property> 
					<name>yarn.resourcemanager.address</name> 
					<value>master:8032</value> 
				</property> 
				<property> 
					<name>yarn.resourcemanager.scheduler.address</name>
					<value>master:8030</value> 
				</property>
			 </configuration>

	-sudo vi /etc/hosts
		-add the following to the hosts file
			10.0.0.4 master 
			10.0.0.5 slave01 
			10.0.0.6 slave02
	-Install Numpy
		-sudo apt-get install python2.7-dev
		-sudo apt-get install python-pip
		-sudo pip install numpy
	-Install other packages that you will commonly need (you can still install packages later, but it will take longer)
	-sudo waagent -deprovision
	-exit
	-Shutdown hdimage from the management portal by clicking on the command bar
	-when hdimage is stopped, click capture to open the Capture the Virtual Machine dialog box
		-give the Image Name: hdimage
		-Click I have run waagent-deprovision on the virtual machine
		-click the check mark to capture the image

Build the Master
	-Click the New button 
	-Click Virtual Machine 
	-Select From Gallery
	-Select from My Images: hdimage
	-click the right arrow
	-Enter the following parameters in the Virtual machine configuration
		-VIRTUAL MACHINE NAME: master
		-SIZE: A1
		-NEW USER NAME: hduser
		-deselect UPLOAD COMPATIBLE SSH KEY FOR AUTHENTICATION
		-select PROVIDE A PASSWORD
		-NEW PASSWORD: <your choice>
		-Click the right arrow
	-On the second Virtual machine configuration page
		-Select the CLOUD SERVICE DNS NAME that you previously created 
		-REGION/AFFINITY GROUP/VIRTUAL NETWORK: hadoopnet
		-Virtual Network Subnets: hadoop
		-Add the following endpoints with the following attributes for (Name-Protocol-Public Port-Private Port):
			HDFS-TCP-50070-50070
			Cluster-TCP-8088-8088
			JobHistory-TCP-19888-19888
	-Click the right arrow and then the checkmark 

Build the Slaves
	-Click the New button
	-Click Virtual Machine
	-Select From Gallery
	-Select from My Images: hdimage
	-click the right arrow
	-Enter the following parameters in the Virtual machine configuration
		-VIRTUAL MACHINE NAME: slave01
		-SIZE: A1
		-NEW USER NAME:hduser
		-deselect UPLOAD COMPATIBLE SSH KEY FOR AUTHENTICATION
		-select PROVIDE A PASSWORD
		-NEW PASSWORD: <your choice>
	-Click the right arrow
	-On the second Virtual machine configuration page
		-Select the CLOUD SERVICE DNS NAME that you previously created
		-Virtual Network Subnets: hadoop
		-REGION/AFFINITY GROUP/VIRTUAL NETWORK: hadoopnet
		-Click the right arrow and then the checkmark 
Repeat the above using the VIRTUAL MACHINE NAME slave02

Configure the Master
	-ssh into master (find the IP the same way as above)
	-get prebuilt version of PySpark
		wget http://apache.osuosl.org/spark/spark-1.4.0/spark-1.4.0-bin-hadoop2.6.tgz
		tar -xvzf spark-1.4.0-bin-hadoop2.6.tgz
		mv spark-1.4.0-bin-hadoop2.6 spark
	-vi $HADOOP_HOME/etc/hadoop/slaves
		-add the following entries:
			-slave01
			-slave02
		-remove localhost
	-generate a public key by executing the following:
		ssh-keygen -t rsa -P “”
		cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys
	-Accept the default file name (.ssh/id_rsa)
	-Copy the public key to slave01 and slave02
		ssh-copy-id -i .ssh/id_rsa.pub hduser@slave01
		ssh-copy-id -i .ssh/id_rsa.pub hduser@slave02
	-Check to see if you can passwordless ssh into slave01 by executing:
		ssh hduser@slave01
	-Exit slave01, by typing “exit”
	-Check to see if you can passwordless ssh into slave02 by executing:
		ssh hduser@slave02
	-Exit slave02, by typing “exit”

Format the NameNode on master
	hdfs namenode -format

Start the Cluster
	-Start the namenode:
		hadoop-daemon.sh start namenode
	-Start the datanode:
		hadoop-daemons.sh start datanode
	-Start resource manager on master:
		yarn-daemon.sh start resourcemanager
	-Start node managers on the slaves by running the following on the master:
		yarn-daemons.sh start nodemanager
	-Start the job history server on master:
		mr-jobhistory-daemon.sh start historyserver

Test the Cluster
	hadoop jar /usr/local/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar pi 8 1000
	- The final output should be:
		Estimated value of Pi is 3.141000000000000000000



Using Hadoop Yarn with Spark
from 
	-https://spark.apache.org/docs/latest/running-on-yarn.html
	-http://blog.cloudera.com/blog/2014/05/apache-spark-resource-management-and-yarn-app-models/
	-http://caen.github.io/hadoop/user-spark.html

	Using YARN as Spark’s cluster manager confers a few benefits over Spark standalone 	and Mesos. Spark supports two modes for running on YARN, “yarn-cluster” mode and 	“yarn-client” mode.  Broadly, yarn-cluster mode makes sense for production jobs, 	while yarn-client mode makes sense for interactive and debugging uses where you want 	to see your application’s output immediately.

	Launching Spark on YARN:
	Ensure that HADOOP_CONF_DIR or YARN_CONF_DIR points to the directory which contains 	the (client side) configuration files for the Hadoop cluster. These configs are used 	to write to the dfs and connect to the YARN ResourceManager. The configuration 		contained in this directory will be distributed to the YARN cluster so that all 	containers used by the application use the same configuration. If the configuration 	references Java system properties or environment variables not managed by YARN, they 	should also be set in the Spark application’s configuration (driver, executors, and 	the AM when running in client mode).
	There are two deploy modes that can be used to launch Spark applications on YARN. In 	yarn-cluster mode, the Spark driver runs inside an application master process which 	is managed by YARN on the cluster, and the client can go away after initiating the 	application. In yarn-client mode, the driver runs in the client process, and the 	application master is only used for requesting resources from YARN.
	Unlike in Spark standalone and Mesos mode, in which the master’s address is 		specified in the “master” parameter, in YARN mode the ResourceManager’s address is 	picked up from the Hadoop configuration. Thus, the master parameter is simply “yarn-	client” or “yarn-cluster”.
	
	To launch a Spark application in yarn-cluster mode:
	cd spark
	./bin/spark-submit --class path.to.your.Class --master yarn-cluster [options] <app jar> [app options]

	For example:
	$ ./bin/spark-submit --class org.apache.spark.examples.SparkPi \
    	--master yarn-cluster \
    	--num-executors 3 \
    	--driver-memory 4g \
    	--executor-memory 2g \
    	--executor-cores 1 \
   	--queue thequeue \
    	lib/spark-examples*.jar \
    	10
	The above starts a YARN client program which starts the default Application Master. 	Then SparkPi will be run as a child thread of Application Master. The client will 	periodically poll the Application Master for status updates and display them in the 	console. The client will exit once your application has finished running. Refer to 	the “Debugging your Application” section below for how to see driver and executor 	logs.
	To launch a Spark application in yarn-client mode, do the same, but replace “yarn-	cluster” with “yarn-client”. To run spark-shell:
	$ ./bin/spark-shell --master yarn-client <your application name>
	
	To copy the data you need to HDFS:
		-Make a directory in hadoop for your data:
			hadoop fs -mkdir /user/hduser/<data folder name>
		-Put the data into the folder
			hadoop fs -put spark-1.3.1-bin-hadoop2.6
	
	


