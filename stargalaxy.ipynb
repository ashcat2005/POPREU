{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Random Forest for Star-Galaxy Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code allows us to use PySpark in the iPython Notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Set the path for spark installation\n",
    "# this is the path where you have built spark using sbt/sbt assembly\n",
    "os.environ['SPARK_HOME']=\"/Users/blorangest/Desktop/spark-1.3.1-bin-hadoop2.6\"\n",
    "\n",
    "# Append to PYTHONPATH so that pyspark could be found\n",
    "sys.path.append(\"/Users/blorangest/Desktop/spark-1.3.1-bin-hadoop2.6/python\")\n",
    "sys.path.append(os.path.join(os.environ['SPARK_HOME'], 'python/lib/py4j-0.8.2.1-src.zip'))\n",
    "\n",
    "# Now we are ready to import Spark Modules\n",
    "try:\n",
    "    from pyspark.mllib.tree import RandomForest\n",
    "    from pyspark.mllib.util import MLUtils\n",
    "    from pyspark.mllib.regression import LabeledPoint\n",
    "    from pyspark import SparkContext\n",
    "\n",
    "except ImportError as e:\n",
    "    print (\"Error importing Spark Modules\", e)\n",
    "    sys.exit(1)\n",
    "import numpy as np\n",
    "#import pyfits\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we set some variables that will determine the properties of the random forest. \n",
    "test_size is the percentage of the data that will be used to test the model.\n",
    "num_trees is the number of trees in the forest.\n",
    "max_depth is the maximum depth of each tree. It must be no more than 30.\n",
    "k is the number of folds desired for kfolds cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataFile = \"cfhtlens_matched.csv\"\n",
    "test_size = 0.2\n",
    "num_trees = 6\n",
    "max_depth = 10\n",
    "k = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function saves a given RDD as a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save (rdd, filename):\n",
    "    try:\n",
    "        shutil.rmtree(filename)\n",
    "    except Exception:\n",
    "        pass\n",
    "    rdd.saveAsTextFile(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will be used to add colors to the feature data by taking the differences of adjacent magnitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addColors (features):\n",
    "    for i in range (len(features)-1):\n",
    "        features.append(features[i+1]-features[i])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function does data preprocessing. It removes unwanted columns and puts the relevant data in LabeledPoint objects. Note that, in this particular dataset, one of the columns has comma seperated values enclosed by quotes that all belong under a single heading. This column will be quotes[1]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse (line): \n",
    "    quotes = np.array([x for x in line.split('\"')])\n",
    "    row = quotes[0].split(',')[:-1] + [quotes[1]] + quotes[2].split(',')[1:]\n",
    "    label = float(row[heads['true_class']])\n",
    "    want = ['MAG_u', 'MAG_g', 'MAG_r', 'MAG_i', 'MAG_z']\n",
    "    want_index = []\n",
    "    for w in want:\n",
    "        want_index.append(heads[w])\n",
    "    features = []\n",
    "    for i in range (len(row)):\n",
    "        for w in want_index:\n",
    "            if i == w:\n",
    "                features.append(float(row[i]))\n",
    "    features = addColors(features)\n",
    "    return LabeledPoint(label, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is a slow way to get classification probabilities and number of trees that classify it as a star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_probs (model, data):\n",
    "    # Collect the individual decision trees as JavaArray objects\n",
    "    trees = model._java_model.trees()\n",
    "    ntrees = model.numTrees()\n",
    "    scores = DecisionTreeModel(trees[0]).predict(data.map(lambda x: x.features))\n",
    "\n",
    "    # For each tree, apply its prediction to the entire dataset and zip together the results\n",
    "    for i in range(1,ntrees):\n",
    "        dtm = DecisionTreeModel(trees[i])\n",
    "        scores = scores.zip(dtm.predict(data.map(lambda x: x.features)))\n",
    "        scores = scores.map(lambda x: x[0] + x[1])\n",
    "    \n",
    "    # Divide the accumulated scores over the number of trees\n",
    "    return scores.map(lambda x: x/ntrees), scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute test error by thresholding probabilistic predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def probTest(testData, model):\n",
    "    threshold = 0.5\n",
    "    probsAndScores = get_probs(model,testData)\n",
    "    probs = probsAndScores[0]\n",
    "    pred = probs.map(lambda x: 0 if x < threshold else 1)\n",
    "    lab_pred = testData.map(lambda lp: lp.label).zip(pred)\n",
    "    acc = lab_pred.filter(lambda (v, p): v != p).count() / float(testData.count())\n",
    "    return (1 - acc), probsAndScores[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests the random forest classifier once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testOnce ():\n",
    "    # split the data into training and testing sets\n",
    "    (trainingData, testData) = data.randomSplit([1-test_size, test_size])\n",
    "\n",
    "    # train the random forest\n",
    "    model = RandomForest.trainClassifier(trainingData, numClasses=2, categoricalFeaturesInfo={},\n",
    "                                     numTrees=num_trees, featureSubsetStrategy=\"auto\",\n",
    "                                     impurity='gini', maxDepth = max_depth, maxBins=32)\n",
    "\n",
    "    # test the random forest\n",
    "    predictions = model.predict(testData.map(lambda x: x.features))\n",
    "    labelsAndPredictions = testData.map(lambda lp: lp.label).zip(predictions)\n",
    "    testErr = labelsAndPredictions.filter(lambda (v, p): v != p).count() / float(testData.count())\n",
    "    Mg = float(labelsAndPredictions.filter(lambda (v, p): v == 0 and p == 1).count())\n",
    "    Ng = float(labelsAndPredictions.filter(lambda (v, p): v == 0 and p == 0).count())\n",
    "    Ms = float(labelsAndPredictions.filter(lambda (v, p): v == 1 and p == 0).count())\n",
    "    Ns = float(labelsAndPredictions.filter(lambda (v, p): v == 1 and p == 1).count())\n",
    "    probsAndScores = probTest(testData, model)\n",
    "    threshold_accuracy = probsAndScores[0]\n",
    "    probs = probsAndScores[1].map(lambda x: x/num_trees)\n",
    "    labelsAndPredictions = labelsAndPredictions.zip(probs)\n",
    "    save(labelsAndPredictions, 'answers')\n",
    "    print ('Galaxy Purity = ' + str(Ng / (Ng+Ms)))\n",
    "    print ('Galaxy Completeness = ' + str(Ng / (Ng+Mg)))\n",
    "    print ('Star Purity = ' + str(Ns / (Ns+Mg)))\n",
    "    print ('Star Completeness = ' + str(Ns/(Ns+Ms)))\n",
    "    print ('Accuracy = ' + str(1 - testErr))\n",
    "    print ('Threshold method accuracy = ' + str(threshold_accuracy))\n",
    "    #print(model.toDebugString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performs k folds cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kfolds ():\n",
    "    #folds = kFold(data, k) this would work in java\n",
    "    acc = 0\n",
    "    spurity = 0\n",
    "    scomp = 0\n",
    "    gpurity = 0\n",
    "    gcomp = 0\n",
    "    foldsize = data.count()/k\n",
    "    tested = sc.parallelize([])\n",
    "    for i in range(k):\n",
    "        test = sc.parallelize(data.subtract(tested).takeSample(False, foldsize))\n",
    "        tested = tested.union(test)\n",
    "        train = data.subtract(test)\n",
    "        # train the random forest\n",
    "        model = RandomForest.trainClassifier(train, numClasses=2, categoricalFeaturesInfo={},\n",
    "                                     numTrees=num_trees, featureSubsetStrategy=\"auto\",\n",
    "                                     impurity='gini', maxDepth = max_depth, maxBins=32)\n",
    "\n",
    "        predictions = model.predict(test.map(lambda x: x.features))\n",
    "        labelsAndPredictions = test.map(lambda lp: lp.label).zip(predictions)\n",
    "        testErr = labelsAndPredictions.filter(lambda (v, p): v != p).count() / float(test.count())\n",
    "        Mg = float(labelsAndPredictions.filter(lambda (v, p): v == 0 and p == 1).count())\n",
    "        Ng = float(labelsAndPredictions.filter(lambda (v, p): v == 0 and p == 0).count())\n",
    "        Ms = float(labelsAndPredictions.filter(lambda (v, p): v == 1 and p == 0).count())\n",
    "        Ns = float(labelsAndPredictions.filter(lambda (v, p): v == 1 and p == 1).count())\n",
    "        \n",
    "        gpurity += (Ng / (Ng+Ms))\n",
    "        gcomp += (Ng / (Ng+Mg))\n",
    "        spurity += (Ns / (Ns+Mg))\n",
    "        scomp += (Ns/(Ns+Ms))\n",
    "        acc += (1 - testErr)\n",
    "    \n",
    "    print 'with '+ str(k) + ' folds:'\n",
    "    print ('Average Galaxy Purity = ' + str(gpurity / k))\n",
    "    print ('Average Galaxy Completeness = ' + str(gcomp / k))\n",
    "    print ('Average Star Purity = ' + str(spurity / k))\n",
    "    print ('Average Star Completeness = ' + str(scomp / k))\n",
    "    print ('Average Accuracy = ' + str(acc / k))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with 5 folds:\n",
      "Average Galaxy Purity = 0.972509685337\n",
      "Average Galaxy Completeness = 0.989664204269\n",
      "Average Star Purity = 0.921575722348\n",
      "Average Star Completeness = 0.813163382414\n",
      "Average Accuracy = 0.966664156059\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext(appName=\"stargalaxy\")\n",
    "rawData = sc.textFile(dataFile) # is an RDD with 66389 things\n",
    "header = rawData.first()\n",
    "lines = rawData.filter(lambda x: x != header) #now the header is gone\n",
    "header_split = str(header).split(',')\n",
    "heads = {}\n",
    "for i in range( len(header_split)):\n",
    "    heads[header_split[i]] = i\n",
    "data = lines.map(parse).cache() # RDD of LabeledPoints\n",
    "\n",
    "#testOnce()\n",
    "kfolds()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
